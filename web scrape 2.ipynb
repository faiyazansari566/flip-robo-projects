{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.naukri.com/')\n",
    "\n",
    "insert=driver.find_element_by_xpath(\"//div[@class='sWrap']/div//input[@class='sugInp']\")\n",
    "insert.send_keys(\"Data Analyst\")\n",
    "\n",
    "insert1=driver.find_element_by_xpath(\"//div[2]/div//input[@class='sugInp']\")\n",
    "insert1.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "insert2=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "insert2.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "company_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "experience_req=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Job_Title': [], 'Job_Location': [], 'Company_Name': [], 'Experience_Req': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Analyst={}\n",
    "Data_Analyst['Job_Title']=[]\n",
    "Data_Analyst['Job_Location']=[]\n",
    "Data_Analyst['Company_Name']=[]\n",
    "Data_Analyst['Experience_Req']=[]\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in job_title:\n",
    "    Data_Analyst['Job_Title'].append(i.text)\n",
    "print(len(Data_Analyst['Job_Title']))\n",
    "\n",
    "for k in job_location:\n",
    "    Data_Analyst['Job_Location'].append(k.text)\n",
    "print(len(Data_Analyst['Job_Location']))\n",
    "\n",
    "for j in company_name:\n",
    "    Data_Analyst['Company_Name'].append(j.text)\n",
    "print(len(Data_Analyst['Company_Name']))\n",
    "\n",
    "for h in experience_req:\n",
    "    Data_Analyst['Experience_Req'].append(h.text)\n",
    "print(len(Data_Analyst['Experience_Req']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immediate opening For Data Scientist/Data Analyst</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst and Data Analyst</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Chennai, Delhi NCR, Bengaluru</td>\n",
       "      <td>Hk solutions</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intern - DFM Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GLOBALFOUNDRIES Engineering Private Limited</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts on Contract Third party p...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reliability Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Alstom Transport India Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Myntra</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Ladder of changes</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Altisource</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst RE) - Bangalore</td>\n",
       "      <td>Bengaluru(Bellandur)</td>\n",
       "      <td>TELEPERFORMANCE GLOBAL SERVICES</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Immediate opening For Data Scientist/Data Analyst   \n",
       "1                  Business Analyst and Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                          Intern - DFM Data Analyst   \n",
       "4  Hiring Data Analysts on Contract Third party p...   \n",
       "5                           Reliability Data Analyst   \n",
       "6                                Senior Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                    Data Analyst / Business Analyst   \n",
       "9            Hiring For Data Analyst RE) - Bangalore   \n",
       "\n",
       "                          Job_Location  \\\n",
       "0  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1      Delhi NCR, Bengaluru, Hyderabad   \n",
       "2        Chennai, Delhi NCR, Bengaluru   \n",
       "3                            Bengaluru   \n",
       "4                            Bengaluru   \n",
       "5                            Bengaluru   \n",
       "6                            Bengaluru   \n",
       "7                            Bengaluru   \n",
       "8                            Bengaluru   \n",
       "9                 Bengaluru(Bellandur)   \n",
       "\n",
       "                                        Company_Name Experience_Req  \n",
       "0  CAIA-Center For Artificial Intelligence & Adva...        0-3 Yrs  \n",
       "1                                 Tech Mahindra Ltd.       7-12 Yrs  \n",
       "2                                       Hk solutions        0-3 Yrs  \n",
       "3        GLOBALFOUNDRIES Engineering Private Limited        0-5 Yrs  \n",
       "4                  Flipkart Internet Private Limited        2-6 Yrs  \n",
       "5                        Alstom Transport India Ltd.        3-8 Yrs  \n",
       "6                                             Myntra        2-7 Yrs  \n",
       "7                                  Ladder of changes        0-5 Yrs  \n",
       "8                                         Altisource        1-6 Yrs  \n",
       "9                    TELEPERFORMANCE GLOBAL SERVICES        2-6 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(Data_Analyst)\n",
    "df=df.iloc[0:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data_Analyst.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to_window(driver.window_handles[1])\n",
    "driver.close()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[2])\n",
    "driver.close()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "driver.close()\n",
    "driver.switch_to_window(driver.window_handles[0])\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert1=driver.find_element_by_xpath(\"//div[@class='privacyPolicy']/div//button\")\n",
    "insert1.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert2 =driver.find_element_by_xpath(\"//span[@class='fr geoLocBtn later']\")\n",
    "insert2.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "insert3=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input\")\n",
    "insert3.send_keys('Data Analyst')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert4= driver.find_element_by_xpath(\"//div[2][@class='suggestor-location']//div[@class='sWrap']//input\")\n",
    "insert4.send_keys('Bangalore')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert5= driver.find_element_by_xpath(\"//div[@class='qsb-main-content row']//button\")\n",
    "insert5.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert6 = driver.find_elements_by_xpath(\"//div[@class='jobTupleHeader']/div/a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immediate opening For Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Job description\\nDear Candidate\\n\\nSchedule a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst and Data Analyst</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>Job description\\nWe have opening for Data Anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hk solutions</td>\n",
       "      <td>Chennai, Delhi NCR, Bengaluru</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intern - DFM Data Analyst</td>\n",
       "      <td>GLOBALFOUNDRIES Engineering Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts on Contract Third party p...</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\nGreetings from “Altisource bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reliability Data Analyst</td>\n",
       "      <td>Alstom Transport India Ltd.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\nHiring for Data Analyst(RE)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Ladder of changes</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\nHiring for Data Analyst(RE)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Altisource</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Analyst RE) - Bangalore</td>\n",
       "      <td>TELEPERFORMANCE GLOBAL SERVICES</td>\n",
       "      <td>Bengaluru(Bellandur)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst (Telcom domain)</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Immediate opening For Data Scientist/Data Analyst   \n",
       "1                  Business Analyst and Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                          Intern - DFM Data Analyst   \n",
       "4  Hiring Data Analysts on Contract Third party p...   \n",
       "5                           Reliability Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                    Data Analyst / Business Analyst   \n",
       "8            Hiring For Data Analyst RE) - Bangalore   \n",
       "9                       Data Analyst (Telcom domain)   \n",
       "\n",
       "                                        Company Name  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                                 Tech Mahindra Ltd.   \n",
       "2                                       Hk solutions   \n",
       "3        GLOBALFOUNDRIES Engineering Private Limited   \n",
       "4                  Flipkart Internet Private Limited   \n",
       "5                        Alstom Transport India Ltd.   \n",
       "6                                  Ladder of changes   \n",
       "7                                         Altisource   \n",
       "8                    TELEPERFORMANCE GLOBAL SERVICES   \n",
       "9                             Oracle India Pvt. Ltd.   \n",
       "\n",
       "                              Location  \\\n",
       "0  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1      Delhi NCR, Bengaluru, Hyderabad   \n",
       "2        Chennai, Delhi NCR, Bengaluru   \n",
       "3                            Bengaluru   \n",
       "4                            Bengaluru   \n",
       "5                            Bengaluru   \n",
       "6                            Bengaluru   \n",
       "7                            Bengaluru   \n",
       "8                 Bengaluru(Bellandur)   \n",
       "9                            Bengaluru   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job description\\nDear Candidate\\n\\nSchedule a ...  \n",
       "1  Job description\\nWe have opening for Data Anal...  \n",
       "2  Job description\\nRoles and Responsibilities\\nJ...  \n",
       "3  Job description\\nRoles and Responsibilities\\nR...  \n",
       "4  Job description\\nGreetings from “Altisource bu...  \n",
       "5  Job description\\nHiring for Data Analyst(RE)\\n...  \n",
       "6  Job description\\nHiring for Data Analyst(RE)\\n...  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Title = []\n",
    "Location = []\n",
    "Company_Name = []\n",
    "Full_Job_Description = []\n",
    "\n",
    "#Extracting Job title data\n",
    "for aa in Task6:\n",
    "    b  = aa.text\n",
    "    Job_Title.append(b)\n",
    "    \n",
    "# Putting Data in dataframe   \n",
    "Job_Title = pd.DataFrame(Job_Title)\n",
    "Job_Title = Job_Title.rename({ 0 : 'Job Title'},axis = 1 )\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Extracting company name data \n",
    "insert7 = driver.find_elements_by_xpath(\"//div[@class='info fleft']//a[@class='subTitle ellipsis fleft']\")\n",
    "time.sleep(5)\n",
    "for qq in insert7:\n",
    "    z = qq.text\n",
    "    Company_Name.append(z)\n",
    "\n",
    "#Making DataFrame\n",
    "Company_Name = pd.DataFrame(Company_Name)\n",
    "Company_Name= Company_Name.rename({0 : 'Company Name'}, axis=1  )\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Location Data\n",
    "insert8 = driver.find_elements_by_xpath(\"//ul[@class='mt-7']//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for xc in insert8:\n",
    "    ii = xc.text\n",
    "    Location.append(ii)\n",
    "    \n",
    "Location =pd.DataFrame(Location)\n",
    "Location=Location.rename( columns = { 0 : 'Location'} )\n",
    "\n",
    "time.sleep(4)\n",
    "insert9 = driver.find_element_by_xpath(\"//div[@class='content']/section//article/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert9.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert10 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[2]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert10.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert11 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[3]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert11.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert12 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[5]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert12.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert13 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[6]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert13.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert14 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[7]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert14.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert15 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[8]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert15.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert16 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[9]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert16.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert17 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[10]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert17.click()\n",
    "\n",
    "time.sleep(4)\n",
    "insert18 = driver.find_element_by_xpath(\"//div[@class='content']/section//article[11]/div[@class='jobTupleHeader']//a[@class='title fw500 ellipsis']\")\n",
    "insert18.click()\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[10])\n",
    "#Extracting  Description\n",
    "insert20 = driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\")\n",
    "Desc1 =[]\n",
    "for hj in insert20:\n",
    "    ko =hj.text\n",
    "    Desc1.append(ko)\n",
    "    \n",
    "desc1=pd.DataFrame(Desc1)\n",
    "time.sleep(4)\n",
    "\n",
    "#Extracting  Description\n",
    "driver.switch_to_window(driver.window_handles[9])\n",
    "\n",
    "Desc2 =[]\n",
    "Desc3 = []\n",
    "Desc4 = []\n",
    "Desc5 = []\n",
    "Desc6 = []\n",
    "Desc7 = []\n",
    "Desc8 = []\n",
    "Desc9 = []\n",
    "Desc10 = []\n",
    "\n",
    "# Extracting  Description\n",
    "insert21 = driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\")\n",
    "for kl in insert21:\n",
    "    zx = kl.text\n",
    "    Desc2.append(zx)\n",
    "desc2=pd.DataFrame(Desc2)\n",
    "\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[8])\n",
    "time.sleep(4)\n",
    "\n",
    "# Extracting  job Description\n",
    "insert22 = driver.find_elements_by_xpath(\"//div[@class='entry-content-wrapper clearfix']//div[@class='clearboth description']\")\n",
    "for cv in insert22:\n",
    "    bn= cv.text\n",
    "    Desc3.append(bn)\n",
    "\n",
    "desc3 = pd.DataFrame(Desc3)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[7])\n",
    "time.sleep(4)\n",
    "\n",
    "insert23 = driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\")\n",
    "for mn in insert23:\n",
    "    qe = mn.text\n",
    "    Desc4.append(qe)\n",
    "    \n",
    "desc4 = pd.DataFrame(Desc4)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[6])\n",
    "insert24= driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\" )\n",
    "\n",
    "for wr in insert24:\n",
    "    et = wr.text\n",
    "    Desc5.append(et)\n",
    "\n",
    "desc5=pd.DataFrame(Desc5)\n",
    "\n",
    "time.sleep(4)\n",
    "driver.switch_to_window(driver.window_handles[5])\n",
    "\n",
    "#Getting Job Description\n",
    "insert25 =driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\")\n",
    "for yi in insert25:\n",
    "    uo = yi.text\n",
    "    Desc6.append(uo)\n",
    "    \n",
    "desc6 = pd.DataFrame(Desc6)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[4])\n",
    "\n",
    "insert26 = driver.find_elements_by_xpath(\"//section[@class='job-desc']\")\n",
    "for ipk in insert26:\n",
    "    adj = ipk.text\n",
    "    Desc7.append(adj)\n",
    "    \n",
    "desc7= pd.DataFrame(Desc7)\n",
    "\n",
    "#Extracting Job Description\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[3])\n",
    "\n",
    "insert27 = driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\")\n",
    "for ihl in insert27:\n",
    "    adjd = ihl.text\n",
    "    Desc8.append(adjd)\n",
    "    \n",
    "desc8 = pd.DataFrame(Desc8)\n",
    "\n",
    "#Extracting  Job Description\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[2])\n",
    "\n",
    "insert28 = driver.find_elements_by_xpath(\"//div[@class='jd-container']//section[@class='job-desc']\")\n",
    "for kl in insert28:\n",
    "    ad = kl.text\n",
    "    Desc9.append(ad)\n",
    "    \n",
    "desc9 = pd.DataFrame(Desc9)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "#Extracting  Job Description\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "insert29 = driver.find_elements_by_xpath(\"//div[@class='clearboth description']\")\n",
    "for fk in insert29:\n",
    "    al = fk.text\n",
    "    Desc10.append(al)\n",
    "    \n",
    "desc10 = pd.DataFrame(Desc10)\n",
    "\n",
    "# Extracting Complete job descrption data \n",
    "Job_Description = pd.concat([desc1,desc2,desc3,desc4,desc5,desc6,desc7,desc8,desc9,desc10], axis=0)\n",
    "Job_Description.index=range(7)\n",
    "Job_Description=Job_Description.rename(columns ={ 0 : 'Job Description'})\n",
    "\n",
    "Job_Title1 = Job_Title.iloc[0:10]\n",
    "Company_Name1 =Company_Name.iloc[0:10]\n",
    "Location1 = Location.iloc[0:10]\n",
    "\n",
    "#Extracting complete data \n",
    "Naukri_2= pd.concat([Job_Title1,Company_Name1,Location1,Job_Description], axis=1)\n",
    "Naukri_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hk solutions</td>\n",
       "      <td>Chennai, Delhi NCR, Bengaluru</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Spectral Consultants</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Ghaziabad, Gurgaon</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MIS Executive / Data Analyst / Research Analyt...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Greater Noida, Gurgaon</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst / Business Analytics / Fresher An...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Snaphunt</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - Protiviti Gurgaon</td>\n",
       "      <td>Protiviti India Member Private limited</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MIS Executive / Data Analyst / Research Analyt...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SQL Data Analyst</td>\n",
       "      <td>4bell Technology</td>\n",
       "      <td>Delhi/NCR Delhi NCR</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                       Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4  MIS Executive / Data Analyst / Research Analyt...   \n",
       "5  Data Analyst / Business Analytics / Fresher An...   \n",
       "6                                       Data Analyst   \n",
       "7                   Data Analyst - Protiviti Gurgaon   \n",
       "8  MIS Executive / Data Analyst / Research Analyt...   \n",
       "9                                   SQL Data Analyst   \n",
       "\n",
       "                             Company Name                           Location  \\\n",
       "0                            Hk solutions      Chennai, Delhi NCR, Bengaluru   \n",
       "1                                  Netomi                            Gurgaon   \n",
       "2                    Spectral Consultants                            Gurgaon   \n",
       "3               GABA Consultancy services      Delhi NCR, Ghaziabad, Gurgaon   \n",
       "4               GABA Consultancy services  Delhi NCR, Greater Noida, Gurgaon   \n",
       "5               GABA Consultancy services          Delhi NCR, Noida, Gurgaon   \n",
       "6                                Snaphunt                          Delhi NCR   \n",
       "7  Protiviti India Member Private limited                            Gurgaon   \n",
       "8               GABA Consultancy services    Faridabad, Delhi NCR, Ghaziabad   \n",
       "9                        4bell Technology                Delhi/NCR Delhi NCR   \n",
       "\n",
       "  Experience  \n",
       "0    0-3 Yrs  \n",
       "1    0-1 Yrs  \n",
       "2    3-6 Yrs  \n",
       "3    0-0 Yrs  \n",
       "4    0-5 Yrs  \n",
       "5    0-5 Yrs  \n",
       "6    2-5 Yrs  \n",
       "7    1-6 Yrs  \n",
       "8    0-5 Yrs  \n",
       "9    2-7 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.naukri.com/')\n",
    "\n",
    "Job_Title = []\n",
    "Location = []\n",
    "Company_Name = []\n",
    "Experience_Required = []\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "driver.close()\n",
    "time.sleep(2)\n",
    "driver.switch_to_window(driver.window_handles[2])\n",
    "driver.close()\n",
    "time.sleep(4)\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "driver.close()\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "driver.switch_to_window(driver.window_handles[0])\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "Task1=driver.find_element_by_xpath(\"//div[@class='privacyPolicy']/div//button\")\n",
    "Task1.click()\n",
    "\n",
    "time.sleep(20)\n",
    "\n",
    "Task2 =driver.find_element_by_xpath(\"//span[@class='fr geoLocBtn later']\")\n",
    "Task2.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task3=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input\")\n",
    "Task3.send_keys('Data Analyst')\n",
    "\n",
    "time.sleep(5)\n",
    "Task5= driver.find_element_by_xpath(\"//div[@class='qsb-main-content row']//button\")\n",
    "Task5.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task6= driver.find_element_by_xpath(\"//div[@class='filters']/div[2]/div[2]/div[2]/label/i\")\n",
    "Task6.click()\n",
    "\n",
    "time.sleep(10)\n",
    "Task7= driver.find_element_by_xpath(\"//div[@class='filters']/div[3]/div[2]/div[2]/label/i\")\n",
    "Task7.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting Job Title data \n",
    "Task8 = driver.find_elements_by_xpath(\"//div[@class='jobTupleHeader']/div/a\")\n",
    "for aa in Task8:\n",
    "    bb  = aa.text\n",
    "    Job_Title.append(bb)\n",
    "    \n",
    "Job_Title = pd.DataFrame(Job_Title)\n",
    "Job_Title = Job_Title.rename({ 0 : 'Job Title'} , axis = 1 )\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Extracting  company name \n",
    "Task9 = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
    "\n",
    "for cc in Task9:\n",
    "    kk = cc.text\n",
    "    Company_Name.append(kk)\n",
    "Company_Name\n",
    "\n",
    "Company_Name = pd.DataFrame(Company_Name)\n",
    "Company_Name= Company_Name.rename({0 : 'Company Name'}, axis=1  )\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Extracting  Location Data\n",
    "Task10 = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "for jj in Task10:\n",
    "    vv = jj.text\n",
    "    Location.append(vv)\n",
    "Location[0:5]\n",
    "\n",
    "Location =pd.DataFrame(Location)\n",
    "Location=Location.rename( columns = { 0 : 'Location'} )\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Extracting  Experience required data \n",
    "Task11= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for pp in Task11:\n",
    "    g = pp.text\n",
    "    Experience_Required.append(g)\n",
    "    \n",
    "Experience_Required = pd.DataFrame(Experience_Required)\n",
    "Experience_Required  = Experience_Required.rename(columns = { 0 : 'Experience'})\n",
    "\n",
    "\n",
    "#Extracting Final Data \n",
    "Naukri_Jobs = pd.concat([Job_Title,Company_Name,Location ,Experience_Required ] ,axis=1)\n",
    "Naukri_Jobs3 =Naukri_Jobs.iloc[0:10]\n",
    "Naukri_Jobs3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Days Posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J.P. Morgan</td>\n",
       "      <td>2d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paypal</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interactions</td>\n",
       "      <td>25d</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gainsight</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mercedes-Benz Research and Development India P...</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>10d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NetApp</td>\n",
       "      <td>19d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J.P. Morgan</td>\n",
       "      <td>23d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TATA Consultancy Services Ltd.</td>\n",
       "      <td>17d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>5d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Days Posted Rating\n",
       "0                                        J.P. Morgan          2d      4\n",
       "1                                             Paypal          3d    3.7\n",
       "2                                       Interactions         25d    3.4\n",
       "3                                          Gainsight         24h    4.2\n",
       "4  Mercedes-Benz Research and Development India P...          9d    3.8\n",
       "5                                             Amazon         10d    4.3\n",
       "6                                             NetApp         19d      4\n",
       "7                                        J.P. Morgan         23d      4\n",
       "8                     TATA Consultancy Services Ltd.         17d    3.8\n",
       "9                                 Ericsson-Worldwide          5d      4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.glassdoor.co.in/index.htm')\n",
    "\n",
    "\n",
    "\n",
    "Company_Name = []\n",
    "Job_Posting_Days = []\n",
    "Rating = []\n",
    "\n",
    "Task1=driver.find_element_by_xpath(\"//div[@class='locked-home-sign-in']\")\n",
    "Task1.click()\n",
    "time.sleep(5)\n",
    "Task2=driver.find_element_by_xpath(\"//div[@class='minh-modal d-flex flex-column justify-content-between fullHeight mw-400']/div/div/div[3]//div[1]//input\")\n",
    "Task2.send_keys('susmita09@gmail.com')\n",
    "time.sleep(5)\n",
    "Task3=driver.find_element_by_xpath(\"//div[@class='minh-modal d-flex flex-column justify-content-between fullHeight mw-400']/div/div/div[3]//div[2]//input\")\n",
    "Task3.send_keys('xyz12345')\n",
    "time.sleep(5)\n",
    "Task4=driver.find_element_by_xpath(\"//button[@class='gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "Task4.click()\n",
    "time.sleep(5)\n",
    "Task5 = driver.find_element_by_xpath(\"//div[@class='d-flex col-6 p-0 SearchStyles__searchKeywordContainer']/div//input\")\n",
    "Task5.send_keys('Data Scientist')\n",
    "time.sleep(5)\n",
    "Task6 = driver.find_element_by_xpath(\"//div[@class='ml-xsm col-4 p-0 headerSearchInput SearchStyles__searchBarLocationInput css-1ohf0ui']/div[@class='input-wrapper css-q444d9']/input\")\n",
    "Task6.send_keys('Noida')\n",
    "time.sleep(5)\n",
    "Task7 =driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto css-iixdfr']/span\")\n",
    "Task7.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting  company data \n",
    "\n",
    "Task8 = driver.find_elements_by_xpath(\"//div[@class='jobHeader d-flex justify-content-between align-items-start']/a\")\n",
    "Task8\n",
    "for fr in Task8:\n",
    "    gf = fr.text\n",
    "    Company_Name.append(gf)\n",
    "    \n",
    "Company_Name1= pd.DataFrame(Company_Name)\n",
    "Company_Name1 = Company_Name1.rename(columns = {0 : 'Company Name'})\n",
    "Company_Name1\n",
    "\n",
    "# Extracting  No of Days job posted data \n",
    "Task8 = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between css-1qtdns2']//div[@class='d-flex align-items-end pl-std css-mi55ob']\")  if driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between css-1qtdns2']//div[@class='d-flex align-items-end pl-std css-mi55ob']\") else '-' \n",
    "Task8\n",
    "\n",
    "for hy in Task8:\n",
    "    se = hy.text\n",
    "    Job_Posting_Days.append(se)\n",
    "    \n",
    "Job_Posting_Days1 = pd.DataFrame(Job_Posting_Days)\n",
    "Days_Posted =Job_Posting_Days1.rename(columns = { 0 : 'Days Posted'})\n",
    "\n",
    "# Extracting  company rating data \n",
    "Task9 = driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "\n",
    "for bg in Task9:\n",
    "    pi = bg.text\n",
    "    Rating.append(pi)\n",
    "    \n",
    "Rating1 = pd.DataFrame(Rating)\n",
    "Rating2=Rating1.rename(columns  = {0 : 'Rating'} )\n",
    "\n",
    "Company_Name2 = Company_Name1.iloc[0:10]\n",
    "Days_Posted1 = Days_Posted.iloc[0:10]\n",
    "Rating3 = Rating2.iloc[0:10]\n",
    "\n",
    "# Extracting  complete Data scientist job Data From glassdoor.\n",
    "Data_Scientist_Glassdoor  = pd.concat([Company_Name2 ,Days_Posted1 , Rating3] , axis=1)\n",
    "Data_Scientist_Glassdoor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Martin</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (Fr...</td>\n",
       "      <td>₹294</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Others Oval Sunglasses (53)</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARNETTE</td>\n",
       "      <td>Mirrored, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹3,514</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fossil</td>\n",
       "      <td>UV Protection, Polarized Aviator Sunglasses (F...</td>\n",
       "      <td>₹3,520</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shadz</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹190</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rylie</td>\n",
       "      <td>UV Protection Aviator, Wayfarer Sunglasses (Fr...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Trendy Glasses</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹228</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JUST STYLE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹118</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LEZTO</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price  \\\n",
       "0     David Martin  Gradient, UV Protection Aviator Sunglasses (Fr...    ₹294   \n",
       "1   ROZZETTA CRAFT                        Others Oval Sunglasses (53)    ₹404   \n",
       "2          ARNETTE      Mirrored, UV Protection Round Sunglasses (50)  ₹3,514   \n",
       "3           Fossil  UV Protection, Polarized Aviator Sunglasses (F...  ₹3,520   \n",
       "4     Singco India      UV Protection Wayfarer Sunglasses (Free Size)    ₹189   \n",
       "..             ...                                                ...     ...   \n",
       "15           shadz  UV Protection Retro Square Sunglasses (Free Size)    ₹190   \n",
       "16           Rylie  UV Protection Aviator, Wayfarer Sunglasses (Fr...    ₹284   \n",
       "17  Trendy Glasses         UV Protection Round Sunglasses (Free Size)    ₹228   \n",
       "18      JUST STYLE              UV Protection Aviator Sunglasses (57)    ₹118   \n",
       "19           LEZTO         UV Protection Round Sunglasses (Free Size)    ₹179   \n",
       "\n",
       "   Discount  \n",
       "0   78% off  \n",
       "1   79% off  \n",
       "2   45% off  \n",
       "3   20% off  \n",
       "4   72% off  \n",
       "..      ...  \n",
       "15  85% off  \n",
       "16  81% off  \n",
       "17  82% off  \n",
       "18  60% off  \n",
       "19  81% off  \n",
       "\n",
       "[82 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "time.sleep(3)\n",
    "Task1 =driver.find_element_by_xpath(\"//div[@class='_3Njdz7']/button\")\n",
    "Task1.click()\n",
    "time.sleep(3)\n",
    "Task2 = driver.find_element_by_xpath(\"//div[@class='O8ZS_U']/input\")\n",
    "Task2.send_keys('Sunglasses')\n",
    "time.sleep(3)\n",
    "Task3 = driver.find_element_by_xpath(\"//button[@class='vh79eN']\")\n",
    "Task3.click()\n",
    "time.sleep(5)\n",
    "\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Product_Description1 = []\n",
    "Price  = []\n",
    "Discount = []\n",
    "\n",
    "#Extracting Brand Data \n",
    "Task4 =driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "for  p in Task4:\n",
    "    y = p.text\n",
    "    Brand.append(y)\n",
    "    \n",
    "Brand1 = pd .DataFrame(Brand)\n",
    "Brand1 = Brand1.rename(columns = { 0 : 'Brand'})\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting product description\n",
    "Task5 =driver.find_elements_by_xpath(\"//a[@class='_2mylT6']\")\n",
    "for n in Task5:\n",
    "    uy = n.text\n",
    "    Product_Description.append(uy)\n",
    "    \n",
    "Product_Description1 = pd.DataFrame(Product_Description)\n",
    "Product_Description1 = Product_Description1.rename(columns = { 0 : 'Product Description'} )\n",
    "\n",
    "time.sleep(3)\n",
    "#Extracting Price Data\n",
    "Task6 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "for e in Task6:\n",
    "    rt = e.text\n",
    "    Price.append(rt)\n",
    "Price1 = pd.DataFrame(Price)\n",
    "Price1 = Price1.rename(columns = { 0: 'Price'} )\n",
    "time.sleep(5)\n",
    "Task7 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\") \n",
    "for tr in Task7:\n",
    "    qz =  tr.text\n",
    "    Discount.append(qz)\n",
    "    \n",
    "time.sleep(3)\n",
    "Discount1 = pd.DataFrame(Discount)\n",
    "Discount1 = Discount1.rename({ 0 : 'Discount'} , axis =1)\n",
    "time.sleep(3)\n",
    "\n",
    "Brand2 = Brand1.iloc[0:38]\n",
    "Product_Description2 = Product_Description1.iloc[0:38]\n",
    "Price2 = Price1.iloc[0:38]\n",
    "Discount2 = Discount1.iloc[0:38]\n",
    "sun =pd.concat([Brand2, Product_Description2,Price2, Discount2],axis=1)\n",
    "\n",
    "time.sleep(5)\n",
    "Task8 = driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[2]\")\n",
    "Task8.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "Brand4 = []\n",
    "Product_Description4 = []\n",
    "Price4 = []\n",
    "Discount4 = []\n",
    "time.sleep(5)\n",
    "\n",
    "# Extracting  Brand data of second page\n",
    "Task9 =driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "for  byx in Task9:\n",
    "    qdx = byx.text\n",
    "    Brand4.append(qdx)\n",
    "Brand5 = pd .DataFrame(Brand4)\n",
    "Brand6 = Brand5.rename(columns = { 0 : 'Brand'})\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Production Description data\n",
    "Task10 =driver.find_elements_by_xpath(\"//a[@class='_2mylT6']\")\n",
    "Task10[0:5]\n",
    "\n",
    "for qzq in Task10:\n",
    "    mqq = qzq.text\n",
    "    Product_Description4.append(mqq)\n",
    "Product_Description5 = pd.DataFrame(Product_Description4)\n",
    "Product_Description6 = Product_Description5.rename(columns = { 0 : 'Product Description'}  )\n",
    "time.sleep(3)\n",
    "\n",
    "Task11 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "for qma in Task11:\n",
    "    apa = qma.text\n",
    "    Price4.append(apa)\n",
    "Price5 = pd.DataFrame(Price4)\n",
    "Price6= Price5.rename(columns = { 0: 'Price'} )\n",
    "time.sleep(3)\n",
    "\n",
    "Task12 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\")\n",
    "for cyz in Task12:\n",
    "    qzz =  cyz.text\n",
    "    Discount4.append(qzz)\n",
    "Discount5 = pd.DataFrame(Discount4)\n",
    "Discount6 = Discount5.rename(columns = { 0 : 'Discount'})\n",
    "\n",
    "Brand7 = Brand6.iloc[0:33]\n",
    "Product_Description7 = Product_Description6.iloc[0:33]\n",
    "Price7 = Price6.iloc[0:33]\n",
    "Discount7 = Discount6.iloc[0:33]\n",
    "sun1 =pd.concat([Brand7,Product_Description7,Price7,Discount7],axis=1)\n",
    "\n",
    "time.sleep(4)\n",
    "Task13 = driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[4]\")\n",
    "Task13.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting  Brand Data from second Page\n",
    "Task14 =driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "Brand10 = []\n",
    "Product_Description10 = []\n",
    "Price10 = []\n",
    "Discount10  = []\n",
    "for  byf in Task14:\n",
    "    qdf = byf.text\n",
    "    Brand10.append(qdf)\n",
    "\n",
    "Brand11 = pd .DataFrame(Brand10)\n",
    "Brand12 = Brand11.rename(columns = { 0 : 'Brand'})\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting  Product description data \n",
    "Task15 =driver.find_elements_by_xpath(\"//a[@class='_2mylT6']\") \n",
    "\n",
    "for qzm in Task15:\n",
    "    mqm = qzm.text\n",
    "    Product_Description10.append(mqm)\n",
    "\n",
    "Product_Description11= pd.DataFrame(Product_Description10)\n",
    "Product_Description12 = Product_Description11.rename(columns = { 0 : 'Product Description'}  )\n",
    "time.sleep(5)\n",
    "Task16 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "for qmw in Task16:\n",
    "    apw = qmw.text\n",
    "    Price10.append(apw)\n",
    "Price11 = pd.DataFrame(Price10)\n",
    "Price12 = Price11.rename(columns = { 0: 'Price'} )\n",
    "time.sleep(5)\n",
    "Task17 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\") \n",
    "for cyh in Task17:\n",
    "    qzh =  cyh.text\n",
    "    Discount10.append(qzh)\n",
    "Discount11 = pd.DataFrame(Discount10)\n",
    "Discount12 = Discount11.rename({ 0 : 'Discount'} , axis =1)\n",
    "\n",
    "\n",
    "Brand13 = Brand12.iloc[0:29]\n",
    "Product_Description13 = Product_Description12.iloc[0:29]\n",
    "Price13  =Price12.iloc[0:29]\n",
    "Discount13  = Discount12.iloc[0:29] \n",
    "sun2 =pd.concat([Brand13, Product_Description13,Price13, Discount13],axis=1)\n",
    "\n",
    "time.sleep(4)\n",
    "Task18 = driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[5]\")\n",
    "Task18.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting Brand Data from second Page\n",
    "Task19 =driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "Brand15 = []\n",
    "Product_Description15 = []\n",
    "Price15 = []\n",
    "Discount15  = []\n",
    "for  byfx in Task19:\n",
    "    qdfx = byfx.text\n",
    "    Brand15.append(qdfx)\n",
    "\n",
    "Brand16 = pd .DataFrame(Brand15)\n",
    "Brand17 = Brand16.rename(columns = { 0 : 'Brand'})\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting  Product description data \n",
    "Task20 =driver.find_elements_by_xpath(\"//a[@class='_2mylT6']\") \n",
    "\n",
    "for qzmq in Task20:\n",
    "    mqmq = qzmq.text\n",
    "    Product_Description15.append(mqmq)\n",
    "\n",
    "Product_Description16= pd.DataFrame(Product_Description15)\n",
    "Product_Description17 = Product_Description16.rename(columns = { 0 : 'Product Description'}  )\n",
    "time.sleep(5)\n",
    "Task21 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "for qmwa in Task21:\n",
    "    apwa = qmwa.text\n",
    "    Price15.append(apwa)\n",
    "Price16 = pd.DataFrame(Price15)\n",
    "Price17 = Price16.rename(columns = { 0: 'Price'} )\n",
    "time.sleep(5)\n",
    "Task22 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\") \n",
    "for cyhz in Task22:\n",
    "    qzhz =  cyhz.text\n",
    "    Discount15.append(qzhz)\n",
    "Discount16 = pd.DataFrame(Discount15)\n",
    "Discount17 = Discount16.rename({ 0 : 'Discount'} , axis =1)\n",
    "\n",
    "Brand18 = Brand17.iloc[0:20]\n",
    "Product_Description18 = Product_Description17.iloc[0:20]\n",
    "Price18  =Price17.iloc[0:20]\n",
    "Discount18  = Discount17.iloc[0:20] \n",
    "sun4 =pd.concat([Brand18, Product_Description18,Price18, Discount18],axis=1)\n",
    "\n",
    "# Extracting  Final Sunglasses data \n",
    "Sunglasses = pd.concat([sun,sun1,sun2,sun4] , axis=0)\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert=driver.find_element_by_xpath(\"//div[@class='swINJg _3nrCtb']/span\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rating': [], 'Review_summary': [], 'Full_review': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_phone={}\n",
    "I_phone['Rating']=[]\n",
    "I_phone['Review_summary']=[]\n",
    "I_phone['Full_review']=[]\n",
    "I_phone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[4]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for cc in rating:\n",
    "    I_phone['Rating'].append(cc.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bcc in review_summary:\n",
    "    I_phone['Review_summary'].append(bcc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cdc in full_review:\n",
    "    I_phone['Full_review'].append(cdc.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[5]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for acc in rating:\n",
    "    I_phone['Rating'].append(acc.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for zcc in review_summary:\n",
    "    I_phone['Review_summary'].append(zcc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for odc in full_review:\n",
    "    I_phone['Full_review'].append(odc.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[6]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "for acc in rating:\n",
    "    I_phone['Rating'].append(acc.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for zcc in review_summary:\n",
    "    I_phone['Review_summary'].append(zcc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for odc in full_review:\n",
    "    I_phone['Full_review'].append(odc.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[7]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[8]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[9]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "70\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[10]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[12]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page=driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[11]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='hGSR34 E_uFuv']\") \n",
    "\n",
    "review_summary=driver.find_elements_by_xpath(\"//p[@class='_2xg6Ul']\")\n",
    "\n",
    "full_review=driver.find_elements_by_xpath(\"//div[@class='qwjRop']\")\n",
    "\n",
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for ab in rating:\n",
    "    I_phone['Rating'].append(ab.text)\n",
    "print(len(I_phone['Rating']))\n",
    "\n",
    "for bc in review_summary:\n",
    "    I_phone['Review_summary'].append(bc.text)\n",
    "print(len(I_phone['Review_summary']))\n",
    "\n",
    "for cd in full_review:\n",
    "    I_phone['Full_review'].append(cd.text)\n",
    "print(len(I_phone['Full_review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>100% Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>No word to say ..simply Awesome. Love it😘😘😘😘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Excellent phone it’s a pro and value for the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Best Camera, good speakers and I guess green i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Really a giant for battery backup and really g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5     Perfect product!   \n",
       "1       5        Great product   \n",
       "2       5     Perfect product!   \n",
       "3       5   Highly recommended   \n",
       "4       5     Perfect product!   \n",
       "..    ...                  ...   \n",
       "95      5            Excellent   \n",
       "96      5    Terrific purchase   \n",
       "97      5    Worth every penny   \n",
       "98      5  Best in the market!   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                          Full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   It’s a must buy who is looking for an upgrade ...  \n",
       "3   iphone 11 is a very good phone to buy only if ...  \n",
       "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                ...  \n",
       "95                                      100% Original  \n",
       "96       No word to say ..simply Awesome. Love it😘😘😘😘  \n",
       "97  Excellent phone it’s a pro and value for the m...  \n",
       "98  Best Camera, good speakers and I guess green i...  \n",
       "99  Really a giant for battery backup and really g...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(I_phone)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asics</td>\n",
       "      <td>GEL-NANDI Sneakers For Men</td>\n",
       "      <td>₹4,859</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lotto</td>\n",
       "      <td>ATLANTA NEO Sneakers For Men</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹461</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>Classy Sneakers For Men</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Essence</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹374</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual shoe for men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lotto</td>\n",
       "      <td>ATLANTA NEO Sneakers For Men</td>\n",
       "      <td>₹594</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product Description   Price  \\\n",
       "0          Asics                         GEL-NANDI Sneakers For Men  ₹4,859   \n",
       "1          Lotto                       ATLANTA NEO Sneakers For Men    ₹799   \n",
       "2         Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹461   \n",
       "3         Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...    ₹236   \n",
       "4   Stefano Rads                            Classy Sneakers For Men    ₹224   \n",
       "..           ...                                                ...     ...   \n",
       "15       Essence                                   Sneakers For Men    ₹374   \n",
       "16     SCATCHITE                          Sneakers Sneakers For Men    ₹398   \n",
       "17     bluemaker               casual shoe for men Sneakers For Men    ₹399   \n",
       "18      Red Rose                                   Sneakers For Men    ₹399   \n",
       "19         Lotto                       ATLANTA NEO Sneakers For Men    ₹594   \n",
       "\n",
       "   Discount  \n",
       "0   46% off  \n",
       "1   60% off  \n",
       "2   76% off  \n",
       "3   52% off  \n",
       "4   85% off  \n",
       "..      ...  \n",
       "15  62% off  \n",
       "16  60% off  \n",
       "17  60% off  \n",
       "18  60% off  \n",
       "19  70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.flipkart.com/')\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []\n",
    "\n",
    "time.sleep(3)\n",
    "Task1 = driver.find_element_by_xpath(\"//div[@class='_3Njdz7']/button\")\n",
    "Task1.click()\n",
    "time.sleep(5)\n",
    "Task2 = driver.find_element_by_xpath(\"//div[@class='O8ZS_U']/input\")\n",
    "Task2.send_keys('Sneakers')\n",
    "time.sleep(5)\n",
    "Task3 = driver.find_element_by_xpath(\"//button[@class='vh79eN']\")\n",
    "Task3.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#Extracting Brand data from first page\n",
    "Task4 = driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "\n",
    "for c in Task4:\n",
    "    z = c.text\n",
    "    Brand.append(z)\n",
    "    \n",
    "Brand1 = pd.DataFrame(Brand)\n",
    "Brand1 = Brand1.rename(columns = { 0 : 'Brand'})\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Product Description data from first page\n",
    "Task5 = driver.find_elements_by_xpath(\"//div[@class='_2LFGJH']/a[1]\")\n",
    "\n",
    "for m in Task5:\n",
    "    p = m.text\n",
    "    Product_Description.append(p)\n",
    "Product_Description1 = pd.DataFrame(Product_Description)\n",
    "Product_Description1 = Product_Description1.rename({ 0: 'Product Description'} , axis=1 )\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Price data from first page\n",
    "\n",
    "Task6 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "\n",
    "for v in Task6:\n",
    "    mn =v.text\n",
    "    Price.append(mn)\n",
    "    \n",
    "Price1 = pd.DataFrame(Price)\n",
    "Price1 = Price1.rename(columns = { 0 : 'Price'})\n",
    "Price2 = Price1.iloc[0:40]\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Discount data from first page\n",
    "Task7 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\")\n",
    "for ki in Task7:\n",
    "    hi = ki.text\n",
    "    Discount.append(hi)\n",
    "\n",
    "Discount1 = pd.DataFrame(Discount)\n",
    "Discount1 =Discount1.rename(columns = { 0 : 'Discount'})\n",
    "Sneakers1 =pd.concat([Brand1,Product_Description1,Price2,Discount1] , axis=1)\n",
    "time.sleep(5)\n",
    "Task8 = driver.find_element_by_xpath(\"//a[@class='_3fVaIS']/span\")\n",
    "Task8.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Brand3 = []\n",
    "Product_Description3 = []\n",
    "Price3 = []\n",
    "Discount3 = []\n",
    "\n",
    "\n",
    "\n",
    "# Extracting  Brand data from second page\n",
    "Task9 = driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "\n",
    "for cv in Task9:\n",
    "    bn = cv.text\n",
    "    Brand3.append(bn)\n",
    "\n",
    "Brand3 = pd.DataFrame(Brand3)\n",
    "Brand3 = Brand3.rename(columns = { 0 : 'Brand'})\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  product description data from second page\n",
    "Task10 = driver.find_elements_by_xpath(\"//div[@class='_2LFGJH']/a[1]\")\n",
    "\n",
    "for gh in Task10:\n",
    "    jk = gh.text\n",
    "    Product_Description3.append(jk)\n",
    "\n",
    "Product_Description3 = pd.DataFrame(Product_Description3)\n",
    "Product_Description3 = Product_Description3.rename({ 0: 'Product Description'} , axis=1 )\n",
    "\n",
    "# Extracting Price data from second page\n",
    "time.sleep(3)\n",
    "\n",
    "Task11 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "\n",
    "for apvq in Task11:\n",
    "    apxq =apvq.text\n",
    "    Price3.append(apxq)\n",
    "\n",
    "Price3 = pd.DataFrame(Price3)\n",
    "Price3 = Price3.rename(columns = { 0 : 'Price'})\n",
    "\n",
    "\n",
    "Price3 = Price3.iloc[0:40]\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Discount  data from second page\n",
    "Task12 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\")\n",
    "\n",
    "for po in Task12:\n",
    "    hn = po.text\n",
    "    Discount3.append(hn)\n",
    "\n",
    "Discount3 = pd.DataFrame(Discount3)\n",
    "\n",
    "Discount3 =Discount3.rename(columns = { 0 : 'Discount'})\n",
    "time.sleep(2)\n",
    "Sneakers2 =pd.concat([Brand3,Product_Description3,Price3,Discount3] , axis=1)\n",
    "time.sleep(3)\n",
    "Task14 = driver.find_element_by_xpath(\"//nav[@class='_1ypTlJ']/a[3]\")\n",
    "Task14.click()\n",
    "time.sleep(5)\n",
    "\n",
    "Brand4 = []\n",
    "Product_Description4 = []\n",
    "Price4 = []\n",
    "Discount4 = []\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Brand Data from third page\n",
    "Task15 = driver.find_elements_by_xpath(\"//div[@class='_2B_pmu']\")\n",
    "\n",
    "\n",
    "for vf in Task15:\n",
    "    ty = vf.text\n",
    "    Brand4.append(ty)\n",
    "\n",
    "Brand4 = pd.DataFrame(Brand4)\n",
    "Brand4 = Brand4.rename(columns = { 0 : 'Brand'})\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Product Description  Data from third page\n",
    "\n",
    "Task16 = driver.find_elements_by_xpath(\"//div[@class='_2LFGJH']/a[1]\")\n",
    "\n",
    "for xx in Task16:\n",
    "    bb = xx.text\n",
    "    Product_Description4.append(bb)\n",
    "\n",
    "Product_Description4 = pd.DataFrame(Product_Description4)\n",
    "Product_Description4 = Product_Description4.rename({ 0: 'Product Description'} , axis=1 )\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Price data from third page\n",
    "Task17 = driver.find_elements_by_xpath(\"//div[@class='_1uv9Cb']/div[1]\")\n",
    "\n",
    "for de in Task17:\n",
    "    oo =de.text\n",
    "    Price4.append(oo)\n",
    "\n",
    "Price4 = pd.DataFrame(Price4)\n",
    "Price4 = Price4.rename(columns = { 0 : 'Price'})\n",
    "\n",
    "Price4 = Price4.iloc[0:40]\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Discount Data from third page\n",
    "Task18 = driver.find_elements_by_xpath(\"//div[@class='VGWI6T']/span\")\n",
    "\n",
    "for wq in Task18:\n",
    "    ss = wq.text\n",
    "    Discount4.append(ss)\n",
    "\n",
    "Discount4 = pd.DataFrame(Discount4)\n",
    "\n",
    "Discount4 =Discount4.rename(columns = { 0 : 'Discount'})\n",
    "\n",
    "time.sleep(3)\n",
    "Brand6 = Brand4.iloc[0:20]\n",
    "Product_Description6 = Product_Description4.iloc[0:20]\n",
    "Price6 = Price4.iloc[0:20]\n",
    "Discount6 = Discount4.iloc[0:20]\n",
    "time.sleep(3)\n",
    "Sneakers3 =pd.concat([Brand6,Product_Description6,Price6,Discount6] , axis=1)\n",
    "\n",
    "# Extracting  Final 100 Sneakers Data.\n",
    "Sneakers_Final = pd.concat([Sneakers1,Sneakers2,Sneakers3] ,axis=0)\n",
    "Sneakers_Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Price (Rs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men NMD R1 Sneakers</td>\n",
       "      <td>10299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>10990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men FluidFlow Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men ZX 2K Boost Solid Sneakers</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Ballerinas</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Vans</td>\n",
       "      <td>Unisex Sneakers</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Solid Italian Leather Formal Loafers</td>\n",
       "      <td>7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>7419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Mark Nason BLOCK - VARSITY</td>\n",
       "      <td>7199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                          Shoe Description Price (Rs)\n",
       "0   ADIDAS Originals                       Men NMD R1 Sneakers     10299 \n",
       "1               Geox                       Men Leather Loafers      10990\n",
       "2             ADIDAS               Men FluidFlow Running Shoes       7999\n",
       "3   ADIDAS Originals            Men ZX 2K Boost Solid Sneakers     10499 \n",
       "4               Geox                  Women Leather Ballerinas       8499\n",
       "..               ...                                       ...        ...\n",
       "45              Geox               Men Leather Formal Slip-Ons       9490\n",
       "46              Vans                           Unisex Sneakers       6999\n",
       "47    ROSSO BRUNELLO  Men Solid Italian Leather Formal Loafers      7699 \n",
       "48    Tommy Hilfiger                Men Colourblocked Sneakers      7419 \n",
       "49          Skechers            Men Mark Nason BLOCK - VARSITY      7199 \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get(\"https://www.myntra.com/shoes\")\n",
    "\n",
    "Brand = []\n",
    "Shoe_Description = []\n",
    "Price = []\n",
    "\n",
    "Task1 = driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label[@class='common-customCheckbox vertical-filters-label']//div[@class='common-checkboxIndicator']\")\n",
    "Task1.click()\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "Task2 = driver.find_element_by_xpath(\"//ul/li[1][@class='colour-listItem']/label[1]/div\")\n",
    "Task2.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting  Brand Data \n",
    "Task3 = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "\n",
    "for x in Task3:\n",
    "    r = x.text\n",
    "    Brand.append(r)\n",
    "\n",
    "Brand1 = pd.DataFrame(Brand)\n",
    "Brand1 = Brand1.rename({ 0 : 'Brand'} , axis=1)\n",
    "time.sleep(2)\n",
    "\n",
    "# Extracting  Shoe Description Data\n",
    "Task4 = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "\n",
    "for nb in Task4:\n",
    "    bn = nb.text\n",
    "    Shoe_Description.append(bn)\n",
    "    \n",
    "time.sleep(3)   \n",
    "\n",
    "Shoe_Description1 = pd.DataFrame(Shoe_Description)\n",
    "Shoe_Description2=Shoe_Description1.iloc[0:100:2]\n",
    "Shoe_Description2.index=range(50)\n",
    "Shoe_Description2 = Shoe_Description2.rename({ 0 : 'Shoe Description'}, axis=1)\n",
    "\n",
    "time.sleep(2)   \n",
    "\n",
    "# Extracting  Shoe Price data \n",
    "\n",
    "Task5 = driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "\n",
    "for l in Task5:\n",
    "    ok = l.text\n",
    "    Price.append(ok)\n",
    "\n",
    "Price1 = pd.DataFrame(Price)\n",
    "Price1['First'] =Price1[0].str.split(' ').str[0]\n",
    "Price1['Second'] =Price1[0].str.split(' ').str[1]\n",
    "Price1['Last'] =Price1[0].str.split(' ').str[2]\n",
    "Price1['Most Last'] =Price1[0].str.split(' ').str[3]\n",
    "Price1 =Price1.drop([0], axis=1)\n",
    "Price1 =Price1.drop(['Last'], axis=1)\n",
    "Price1 =Price1.drop(['Most Last'], axis=1)\n",
    "Price1['Second'] = Price1['Second'].str.replace( 'Rs.' , ' ' )\n",
    "Price1['Second'] = Price1['Second'].str.replace( '.' , ' ' )\n",
    "Price1= Price1.drop(['First'] , axis= 1)\n",
    "Price2 =Price1.rename(columns = { 'Second' : 'Price (Rs)'})\n",
    "time.sleep(2)   \n",
    "Shoes1 = pd.concat([Brand1 ,Shoe_Description2 , Price2] , axis=1)\n",
    "time.sleep(2)   \n",
    "\n",
    "\n",
    "# Extracting  Brand Data of next page\n",
    "Task6 = driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "Task6.click()\n",
    "\n",
    "Brand4 = [] \n",
    "Shoe_Description4 = [] \n",
    "Price4 = []\n",
    "\n",
    "time.sleep(3)\n",
    "Task7 = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "for ax in Task7:\n",
    "    bh = ax.text\n",
    "    Brand4.append(bh)\n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "Brand4 = pd.DataFrame(Brand4)\n",
    "Brand4 = Brand4.rename({0:'Brand'}, axis =1)\n",
    "\n",
    "time.sleep(2)   \n",
    "\n",
    "# Extracting  Brand Description of next page\n",
    "\n",
    "Task8 = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "for ny in Task8:\n",
    "    mi = ny.text\n",
    "    Shoe_Description4.append(mi)\n",
    "    \n",
    "Shoe_Description4 = pd.DataFrame(Shoe_Description4)\n",
    "Shoe_Description4=Shoe_Description4.iloc[0:100:2]\n",
    "Shoe_Description4.index=range(50)\n",
    "Shoe_Description4 = Shoe_Description4.rename({ 0 : 'Shoe Description'}, axis=1)\n",
    "time.sleep(2) \n",
    "\n",
    "#Extracting  Price Data from next page\n",
    "Task9 = driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "for nv in Task9:\n",
    "    mk = nv.text\n",
    "    Price4.append(mk)\n",
    "Price4 = pd.DataFrame(Price4)\n",
    "\n",
    "Price4['First'] =Price4[0].str.split(' ').str[0]\n",
    "Price4['Second'] =Price4[0].str.split(' ').str[1]\n",
    "Price4['Last'] =Price4[0].str.split(' ').str[2]\n",
    "Price4['Most Last'] =Price4[0].str.split(' ').str[3]\n",
    "\n",
    "Price4=Price4.drop([0], axis=1)\n",
    "Price4 =Price4.drop(['Last'], axis=1)\n",
    "Price4 =Price4.drop(['Most Last'], axis=1)\n",
    "Price4['Second'] = Price4['Second'].str.replace( 'Rs.' , ' ' )\n",
    "Price4['Second'] = Price4['Second'].str.replace( '.' , ' ' )\n",
    "Price4= Price4.drop(['First'] , axis= 1)\n",
    "Price5 =Price4.rename(columns = { 'Second' : 'Price (Rs)'})\n",
    "time.sleep(2) \n",
    "\n",
    "Shoes2 = pd.concat([Brand4 ,Shoe_Description4, Price5] , axis=1)\n",
    "\n",
    "Shoes = pd.concat([Shoes1 , Shoes2] , axis =0)\n",
    "\n",
    "# Extracting Final Shoes Data\n",
    "Shoes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "Title = []\n",
    "Rating = []\n",
    "Price = []\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "Task1 = driver.find_element_by_xpath(\"//div//div[@class='nav-search-field ']/input[@id='twotabsearchtextbox']\")\n",
    "Task1.send_keys('Laptop')\n",
    "time.sleep(2)\n",
    "Task2=driver.find_element_by_xpath(\"//div//span[@class='nav-search-submit-text nav-sprite']/input\")\n",
    "Task2.click()\n",
    "\n",
    "time.sleep(2)\n",
    "Task3=driver.find_element_by_xpath(\"//div/ul/li[17]/span/a/div/label/i\")\n",
    "Task3.click()\n",
    "time.sleep(5)\n",
    "Task3=driver.find_element_by_xpath(\"//div/ul/li[17]/span/a/div/label/i\")\n",
    "Task3.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Extracting  brand Data \n",
    "Task5=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "for yu in Task5:\n",
    "    hj=yu.text\n",
    "    Title.append(hj)\n",
    "\n",
    "Title=pd.DataFrame(Title)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Extracting  price Data\n",
    "Task7=driver.find_elements_by_xpath(\"//div[@class='a-row']/div/a/span[@class='a-price']//span[@class='a-price-whole']\") if ( driver.find_elements_by_xpath(\"//div[@class='a-row']/div/a/span[@class='a-price']//span[@class='a-price-whole']\") ) else (' ')\n",
    "\n",
    "for E in Task7:\n",
    "    t=E.text\n",
    "    Price.append(t)\n",
    "    \n",
    "time.sleep(2)\n",
    "    \n",
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)\n",
    "rating = soup.find_all('span' , class_='a-icon-alt')\n",
    "Rating5 = []\n",
    "for axc in rating:\n",
    "    Rating5.append(axc.get_text())\n",
    "Rating6 = pd.DataFrame(Rating5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title1 =Title.drop([0,1,14,15,28,29] , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title1.index=range(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Renewed) ASUS ZenBook Duo Intel Core i7-10510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Inspiron 3567 Laptop Core i3-7t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7240 12.5-inch Laptop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asus Gaming Laptop ROG Strix G17 i7-10750H(16 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HP 14 10th Gen Intel Core i7 Ultra Thin and Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dell XPS 7590 15.6-inch UHD Display Laptop (9t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Asus Vivo AiO V241FFT-BA002TS 23.8-inch FHD To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Renewed) HP Omen 10th Gen Intel Core i7 Proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Renewed) Dell XPS 9370 13.3-inch FHD Display ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dell 2019 Dell Inspiron 14 5482 14 Inch FHD 2-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Renewed) Dell Latitude E7240 12.5-inch Laptop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 10th Gen 14-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lenovo Legion 5i 10th Gen Intel Core i7 15.6 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lenovo Yoga Slim 7i 10th Gen Intel Core i7 14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1065G7 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop E7250 Intel Cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Laptop Name\n",
       "0   Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...\n",
       "1   (Renewed) ASUS ZenBook Duo Intel Core i7-10510...\n",
       "2   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...\n",
       "4   Dell Alienware m15(R3) 15.6-inch FHD Gaming La...\n",
       "5   (Renewed) Dell Inspiron 3567 Laptop Core i3-7t...\n",
       "7   (Renewed) Dell Latitude E7240 12.5-inch Laptop...\n",
       "8   Asus Gaming Laptop ROG Strix G17 i7-10750H(16 ...\n",
       "9   ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...\n",
       "11  HP 14 10th Gen Intel Core i7 Ultra Thin and Li...\n",
       "12  Dell XPS 7590 15.6-inch UHD Display Laptop (9t...\n",
       "13  MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...\n",
       "14  Asus Vivo AiO V241FFT-BA002TS 23.8-inch FHD To...\n",
       "15  (Renewed) HP Omen 10th Gen Intel Core i7 Proce...\n",
       "16  (Renewed) Dell XPS 9370 13.3-inch FHD Display ...\n",
       "17  Dell 2019 Dell Inspiron 14 5482 14 Inch FHD 2-...\n",
       "18  (Renewed) Dell Latitude E7240 12.5-inch Laptop...\n",
       "19  Lenovo ThinkPad E14 Intel Core i7 10th Gen 14-...\n",
       "20  Lenovo Legion 5i 10th Gen Intel Core i7 15.6 i...\n",
       "21  Lenovo Yoga Slim 7i 10th Gen Intel Core i7 14 ...\n",
       "22  ASUS ZenBook 14 (2020) Intel Core i7-1065G7 10...\n",
       "23  (Renewed) Dell Latitude Laptop E7250 Intel Cor..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title2 =Title1.drop([3,6,10] ,axis=0)\n",
    "Title2.rename(columns ={ 0 : 'Laptop Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title2.index =range(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title3 = Title2.iloc[0:10]\n",
    "Title3 =Title3.rename(columns = { 0 : 'Laptop Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price1 =pd.DataFrame(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price2 = Price1.drop([0,1,14,15,27,28], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price3 = Price2.drop ( [5,8,12] , axis= 0)\n",
    "Price3= Price3.rename(columns = { 0: 'Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price4=Price3.iloc[0:10]\n",
    "Price4.index=range(10)\n",
    "Rating7 =Rating6.iloc[5:25]\n",
    "Rating7.index=range(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating8 = Rating7.iloc[0:10]\n",
    "Rating8= Rating8.rename(columns ={0 :'Rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...</td>\n",
       "      <td>85,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Renewed) ASUS ZenBook Duo Intel Core i7-10510...</td>\n",
       "      <td>1,05,739</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>1,29,990</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>1,99,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Dell Inspiron 3567 Laptop Core i3-7t...</td>\n",
       "      <td>37,900</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Latitude E7240 12.5-inch Laptop...</td>\n",
       "      <td>39,999</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Asus Gaming Laptop ROG Strix G17 i7-10750H(16 ...</td>\n",
       "      <td>1,20,790</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...</td>\n",
       "      <td>73,990</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14 10th Gen Intel Core i7 Ultra Thin and Li...</td>\n",
       "      <td>71,790</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell XPS 7590 15.6-inch UHD Display Laptop (9t...</td>\n",
       "      <td>2,33,000</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop Name     Price  \\\n",
       "0  Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...    85,990   \n",
       "1  (Renewed) ASUS ZenBook Duo Intel Core i7-10510...  1,05,739   \n",
       "2  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  1,29,990   \n",
       "3  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  1,99,990   \n",
       "4  (Renewed) Dell Inspiron 3567 Laptop Core i3-7t...    37,900   \n",
       "5  (Renewed) Dell Latitude E7240 12.5-inch Laptop...    39,999   \n",
       "6  Asus Gaming Laptop ROG Strix G17 i7-10750H(16 ...  1,20,790   \n",
       "7  ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...    73,990   \n",
       "8  HP 14 10th Gen Intel Core i7 Ultra Thin and Li...    71,790   \n",
       "9  Dell XPS 7590 15.6-inch UHD Display Laptop (9t...  2,33,000   \n",
       "\n",
       "               Rating  \n",
       "0  4.1 out of 5 stars  \n",
       "1  3.4 out of 5 stars  \n",
       "2  2.9 out of 5 stars  \n",
       "3  4.1 out of 5 stars  \n",
       "4  3.6 out of 5 stars  \n",
       "5  4.4 out of 5 stars  \n",
       "6  3.8 out of 5 stars  \n",
       "7  3.4 out of 5 stars  \n",
       "8  3.0 out of 5 stars  \n",
       "9  3.5 out of 5 stars  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop_New =pd.concat([Title3 , Price4, Rating8] , axis=1)\n",
    "Laptop_New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\user\\ansari\\Selenium\\chromedriver.exe\"\n",
    "\n",
    "driver=webdriver.Chrome(path)\n",
    "my_page=driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Company_Name = []\n",
    "Salaries = []\n",
    "Average_salary = []\n",
    "Min_Salary = []\n",
    "Max_Salary = []\n",
    "\n",
    "time.sleep(3)\n",
    "insert1= driver.find_element_by_xpath(\"//div[@class='search-bar minimized']/div//input[@class='keyword']\")\n",
    "insert1.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 13,18,563</td>\n",
       "      <td>₹706K</td>\n",
       "      <td>₹11,513K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 9,85,497</td>\n",
       "      <td>₹572K</td>\n",
       "      <td>₹1,300K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,53,602</td>\n",
       "      <td>₹581K</td>\n",
       "      <td>₹2,704K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,23,634</td>\n",
       "      <td>₹710K</td>\n",
       "      <td>₹1,559K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹ 9,97,979</td>\n",
       "      <td>₹785K</td>\n",
       "      <td>₹1,251K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,72,507</td>\n",
       "      <td>₹497K</td>\n",
       "      <td>₹1,140K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>₹ 12,689</td>\n",
       "      <td>₹8K</td>\n",
       "      <td>₹20K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>₹ 21,215</td>\n",
       "      <td>₹14K</td>\n",
       "      <td>₹22K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,77,498</td>\n",
       "      <td>₹480K</td>\n",
       "      <td>₹1,000K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,34,456</td>\n",
       "      <td>₹460K</td>\n",
       "      <td>₹1,598K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Name Average Salary Minimum Salary Maximum Salary\n",
       "0                       Delhivery    ₹ 13,18,563          ₹706K       ₹11,513K\n",
       "1                       Accenture     ₹ 9,85,497          ₹572K        ₹1,300K\n",
       "2                             IBM     ₹ 7,53,602          ₹581K        ₹2,704K\n",
       "3              UnitedHealth Group    ₹ 13,23,634          ₹710K        ₹1,559K\n",
       "4  Cognizant Technology Solutions     ₹ 9,97,979          ₹785K        ₹1,251K\n",
       "5              Valiance Solutions     ₹ 7,72,507          ₹497K        ₹1,140K\n",
       "6              Vidooly Media Tech       ₹ 12,689            ₹8K           ₹20K\n",
       "7                Analytics Vidhya       ₹ 21,215           ₹14K           ₹22K\n",
       "8       Tata Consultancy Services     ₹ 6,77,498          ₹480K        ₹1,000K\n",
       "9              Ericsson-Worldwide     ₹ 7,34,456          ₹460K        ₹1,598K"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "insert2 =driver.find_element_by_xpath(\"//div[@class='search-bar minimized']/div//input[@class='loc']\")\n",
    "insert2.send_keys(\"Noida\")\n",
    "time.sleep(3)\n",
    "\n",
    "insert3 = driver.find_element_by_xpath(\"//div[@class='search-bar minimized']//button\")\n",
    "insert3.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting Company Name Data \n",
    "\n",
    "insert4 = driver.find_elements_by_xpath(\"//div[@class='col-md-6']/div/div[2]//p[2]\")\n",
    "for o in insert4:\n",
    "    l = o.text\n",
    "    Company_Name.append(l)\n",
    "    \n",
    "Company_Name1= pd.DataFrame(Company_Name)\n",
    "Company_Name1= Company_Name1.rename({0 : 'Company Name'},axis =1)\n",
    "\n",
    "# Extracting salaries data \n",
    "insert5 = driver.find_elements_by_xpath(\"//div[@class='col-md-6']/div/div[2]//p[5]\")\n",
    "for ko in insert5:\n",
    "    nb = ko.text\n",
    "    No_Of_Salaries.append(nb)\n",
    "    \n",
    "Salaries1 = pd.DataFrame(Salaries)\n",
    "Salaries1 = Salaries1.rename({0 : 'No Of Salaries'} , axis =1)\n",
    "\n",
    "# Extracting Average Salary\n",
    "insert6 = driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "for bf in insert6:\n",
    "    po = bf.text\n",
    "    Average_salary.append(po)\n",
    "\n",
    "Average_salary1 = pd.DataFrame(Average_salary)\n",
    "Average_salary1  = Average_salary1 .rename({ 0 : 'Average Salary'}, axis=1)\n",
    "\n",
    "# Extracting Minimum Salary Data \n",
    "\n",
    "insert7 = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "for cs in insert7:\n",
    "    mp = cs.text\n",
    "    Min_Salary.append(mp)\n",
    "    \n",
    "Min_Salary1 = pd.DataFrame(Min_Salary)\n",
    "Min_Salary1 = Min_Salary1.rename({ 0 : 'Minimum Salary'},  axis=1)\n",
    "\n",
    "# Extracting Maximum salary data \n",
    "insert8 = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "for pm in insert8:\n",
    "    uy = pm.text\n",
    "    Max_Salary.append(uy)\n",
    "    \n",
    "Max_Salary1 = pd.DataFrame(Max_Salary)\n",
    "Max_Salary1 = Max_Salary1.rename({0 : 'Maximum Salary'}, axis=1)\n",
    "\n",
    "Data_Scientist_Glassdoor_Salaries = pd.concat([Company_Name1,Salaries1,Average_salary1 ,Min_Salary1, Max_Salary1], axis=1)\n",
    "\n",
    "# Extracting Final Data\n",
    "\n",
    "Data_Scientist_Glassdoor_Salaries  = Data_Scientist_Glassdoor_Salaries .iloc[0:10]\n",
    "Data_Scientist_Glassdoor_Salaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
